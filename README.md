# Gen_AI_5_day_Kaggle_meet
#### ğŸ”¬ GenAI Prompt Engineering &amp; LLM Evaluation Lab  Welcome to my 5-day GenAI learning journal! This repository captures my hands-on work with large language models, prompt engineering, and structured output evaluation. Each day is focused on practical experimentation inspired by industry-grade whitepapers and guided notebooks.


## ğŸ§  Topics Covered
- Day 1: Prompting techniques (zero-shot, few-shot, system, role, contextual)
- Day 2: Schema-based outputs, JSON validation, evaluation strategies
- Day 3â€“5: (Coming soon...)

## ğŸ“‚ Included Notebooks
- `day-1-prompting.ipynb`: Prompting techniques for different task types
- `day-1-evaluation-and-structured-output.ipynb`: Structured output generation & validation

## ğŸ› ï¸ Tools & Frameworks
- Vertex AI Studio (Gemini Pro)
- Python & Jupyter
- JSON schema evaluation
- Prompt design best practices

## ğŸ“˜ References
- [Prompt Engineering Whitepaper (Google, Feb 2025)](link-to-pdf)
- [Foundational LLMs & Text Generation (Google, Feb 2025)](link-to-pdf)

## ğŸŒŸ Why this matters
Learning prompt engineering isn't just about writing better promptsâ€”it's about understanding model behavior, structure, and reasoning so we can design smarter, safer, and more useful AI experiences.

---

Stay tuned for Day 2! ğŸš€  
