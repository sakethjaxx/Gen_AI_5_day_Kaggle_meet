Here's an updated version of your `README.md` for your GitHub repo that includes both **Day 1** and **Day 2** in a clean, professional format:

---

# Gen_AI_5_day_Kaggle_meet

#### 🔬 GenAI Prompt Engineering & LLM Evaluation Lab  
Welcome to my 5-day GenAI learning journal! This repository captures my hands-on work with large language models, prompt engineering, embeddings, and structured output evaluation. Each day is focused on practical experimentation inspired by industry-grade whitepapers and guided notebooks.

---

## 🧠 Topics Covered

- **Day 1:** Prompting techniques (zero-shot, few-shot, system, role, contextual)
- **Day 2:** Embeddings, vector databases, text similarity, and RAG-based document Q&A
- **Day 3–5:** Coming soon...

---

## 📂 Included Notebooks

- `day-1-prompting.ipynb`: Prompting strategies for various LLM tasks
- `day-1-evaluation-and-structured-output.ipynb`: JSON output generation, schema validation
- `day-2-document-q-a-with-rag.ipynb`: Retrieval-Augmented Generation (RAG) with embeddings
- `day-2-embeddings-and-similarity-scores.ipynb`: Measuring semantic similarity with embeddings
- `day-2-classifying-embeddings-with-keras.ipynb`: Neural classifier using Keras and embeddings

---

## 🛠️ Tools & Frameworks

- Vertex AI (Gemini Pro, Embedding APIs)
- FAISS, ScaNN, LangChain
- Python, TensorFlow, Keras
- Jupyter, Kaggle Notebooks
- JSON schema evaluation

---

## 📘 References

- [Prompt Engineering Whitepaper (Google, Feb 2025)](link-to-pdf)
- [Foundational LLMs & Text Generation (Google, Feb 2025)](link-to-pdf)
- [Embeddings & Vector Stores Whitepaper (Google, Feb 2025)](link-to-pdf)

---

## 🌟 Why this matters

Learning prompt engineering and embeddings isn't just about syntax—it’s about mastering the semantics of LLMs. Understanding how to control, evaluate, and enhance model behavior helps build smarter, more grounded AI systems. Embeddings power everything from personalized search to semantic classification, and vector databases make it scalable.

---

Stay tuned for Day 3! 🚀

